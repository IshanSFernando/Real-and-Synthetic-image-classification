{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.10","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","collapsed":true,"jupyter":{"outputs_hidden":true},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# example of horizontal shift image augmentation\nfrom numpy import expand_dims\nfrom keras.preprocessing.image import load_img\nfrom keras.preprocessing.image import img_to_array\nfrom keras.preprocessing.image import ImageDataGenerator\nfrom matplotlib import pyplot\n\ntrain_datagen = ImageDataGenerator(\nfeaturewise_center=False,\n    samplewise_center=False,\n    featurewise_std_normalization=False,\n    samplewise_std_normalization=False,\n    zca_whitening=False,\n    zca_epsilon=1e-06,\n    rotation_range=0,\n    width_shift_range=0.0,\n    height_shift_range=0.0,\n    brightness_range=None,\n    shear_range=0.0,\n    zoom_range=0.0,\n    channel_shift_range=0.0,\n    fill_mode='nearest',\n    cval=0.0,\n    horizontal_flip=False,\n    vertical_flip=False,\n    rescale=None,\n    preprocessing_function=None,\n    data_format=None,\n    validation_split = 0.2,\n    dtype=None)\n\nvalid_datagen = ImageDataGenerator(\nfeaturewise_center=False,\n    samplewise_center=False,\n    featurewise_std_normalization=False,\n    samplewise_std_normalization=False,\n    zca_whitening=False,\n    zca_epsilon=1e-06,\n    rotation_range=0,\n    width_shift_range=0.0,\n    height_shift_range=0.0,\n    brightness_range=None,\n    shear_range=0.0,\n    zoom_range=0.0,\n    channel_shift_range=0.0,\n    fill_mode='nearest',\n    cval=0.0,\n    horizontal_flip=False,\n    vertical_flip=False,\n    rescale=None,\n    preprocessing_function=None,\n    data_format=None,\n    validation_split = 0.2,\n    dtype=None)\n\n# prepare iterator\ntrain = train_datagen.flow_from_directory(\n    directory=\"../input/data-generation/data\",\n    target_size=(200, 200),\n    color_mode=\"rgb\",\n    batch_size=64,\n    class_mode=\"categorical\",\n    shuffle=True,\n    subset='training')\n\nvalid = valid_datagen.flow_from_directory(\n    directory=\"../input/data-generation/data\",\n    target_size=(200, 200),\n    color_mode=\"rgb\",\n    batch_size=64,\n    class_mode=\"categorical\",\n    shuffle=True,\n    subset='validation')\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from tensorflow.keras.layers import BatchNormalization\nfrom keras.layers.convolutional import Conv2D\nfrom keras.layers.convolutional import AveragePooling2D\nfrom keras.layers.convolutional import MaxPooling2D\nfrom keras.layers.convolutional import ZeroPadding2D\nfrom keras.layers.core import Activation\nfrom keras.layers.core import Dense\nfrom keras.layers import Flatten\nfrom keras.layers import Input\nfrom keras.models import Model\nfrom keras.layers import add\nfrom keras.regularizers import l2\nfrom keras import backend as K","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class ResNet:\n  @staticmethod\n  def residual_module(data, K, stride, chanDim, red=False,reg=0.0001, bnEps=2e-5, bnMom=0.9):\n    shortcut = data\n    bn1 = BatchNormalization(axis=chanDim, epsilon=bnEps, momentum=bnMom)(data)\n    act1 = Activation(\"relu\")(bn1)\n    conv1 = Conv2D(int(K * 0.25), (1, 1), use_bias=False,kernel_regularizer=l2(reg))(act1)\n   \n    bn2 = BatchNormalization(axis=chanDim, epsilon=bnEps, momentum=bnMom)(conv1)\n    act2 = Activation(\"relu\")(bn2)\n    conv2 = Conv2D(int(K * 0.25), (3, 3), strides=stride, padding=\"same\", use_bias=False,kernel_regularizer=l2(reg))(act2)\n    \n    bn3 = BatchNormalization(axis=chanDim, epsilon=bnEps,momentum=bnMom)(conv2)\n    act3 = Activation(\"relu\")(bn3)\n    conv3 = Conv2D(K, (1, 1), use_bias=False, kernel_regularizer=l2(reg))(act3)\n\n    if red:\n      shortcut = Conv2D(K, (1, 1), strides=stride, use_bias=False,kernel_regularizer=l2(reg))(act1)\n    x = add([conv3, shortcut])\n    return x\n\n  @staticmethod\n  def build(width, height, depth, classes, stages, filters,reg=0.0001, bnEps=2e-5, bnMom=0.9):  \n    inputShape = (height, width, depth)\n    chanDim = -1\n    if K.image_data_format() == \"channels_first\":\n      inputShape = (depth, height, width)\n      chanDim = 1 \n\n    inputs = Input(shape=inputShape)\n    x = BatchNormalization(axis=chanDim, epsilon=bnEps,momentum=bnMom)(inputs)\n    x = Conv2D(filters[0], (5, 5), use_bias=False,padding=\"same\", kernel_regularizer=l2(reg))(x)\n    x = BatchNormalization(axis=chanDim, epsilon=bnEps,momentum=bnMom)(x)\n    x = Activation(\"relu\")(x)\n    x = ZeroPadding2D((1, 1))(x)\n    x = MaxPooling2D((3, 3), strides=(2, 2))(x)\n\n    for i in range(0, len(stages)):\n      stride = (1, 1) if i == 0 else (2, 2)\n      x = ResNet.residual_module(x, filters[i + 1], stride, chanDim, red=True, bnEps=bnEps, bnMom=bnMom)\n      for j in range(0, stages[i] - 1):\n        x = ResNet.residual_module(x, filters[i + 1],(1, 1), chanDim, bnEps=bnEps, bnMom=bnMom)\n\n    x = BatchNormalization(axis=chanDim, epsilon=bnEps,momentum=bnMom)(x)\n    x = Activation(\"relu\")(x)\n    x = AveragePooling2D((8, 8))(x)\n    x = Flatten()(x)\n    x = Dense(classes, kernel_regularizer=l2(reg))(x)\n    x = Activation(\"softmax\")(x)\n    \n    model = Model(inputs,x, name=\"resnet\")\n    \n    return model","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"resnet = ResNet.build(200,200,3,2,[3,4,6,6],[64,128,256,512,512])","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"resnet.summary()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import tensorflow as tf\nimport keras\ndef scheduler(epoch, lr):\n    if epoch<10:\n        return lr\n    else:\n        return lr*0.996\n\ncallback = tf.keras.callbacks.LearningRateScheduler(scheduler)\nresnet.compile(\n        optimizer=tf.keras.optimizers.SGD(), loss=\"categorical_crossentropy\", metrics=[\"accuracy\"],run_eagerly=True\n    )\n\n\n#print(tf.keras.utils.plot_model(model))\nhist=resnet.fit(train, validation_data = valid, epochs = 50, batch_size = 64,callbacks=[callback,tf.keras.CSVLogger('epochs.csv')])\n\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"resnet.save(\"model-ishan-last1.h5\")","metadata":{"trusted":true},"execution_count":null,"outputs":[]}]}